{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seg2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sopper08/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sopper08/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of training data(for this seg): 264\n",
      "Sum of testing data(for this seg): 256793\n",
      "---\n",
      "Running seg3 ... \n",
      "Sum of training data(for this seg): 158\n",
      "Sum of testing data(for this seg): 145786\n",
      "---\n",
      "Running seg4 ... \n",
      "Sum of training data(for this seg): 87\n",
      "Sum of testing data(for this seg): 92501\n",
      "---\n",
      "Running seg5 ... \n",
      "Sum of training data(for this seg): 69\n",
      "Sum of testing data(for this seg): 62787\n",
      "---\n",
      "Running seg6 ... \n",
      "Sum of training data(for this seg): 54\n",
      "Sum of testing data(for this seg): 44630\n",
      "---\n",
      "Running seg7 ... \n",
      "Sum of training data(for this seg): 30\n",
      "Sum of testing data(for this seg): 32606\n",
      "---\n",
      "Running seg8 ... \n",
      "Sum of training data(for this seg): 19\n",
      "Sum of testing data(for this seg): 24601\n",
      "---\n",
      "Running seg9 ... \n",
      "Sum of training data(for this seg): 15\n",
      "Sum of testing data(for this seg): 18892\n",
      "---\n",
      "Running seg10 ... \n",
      "Sum of training data(for this seg): 14\n",
      "Sum of testing data(for this seg): 14749\n",
      "---\n",
      "Running seg11 ... \n",
      "Sum of training data(for this seg): 12\n",
      "Sum of testing data(for this seg): 11759\n",
      "---\n",
      "Running seg12 ... \n",
      "Sum of training data(for this seg): 12\n",
      "Sum of testing data(for this seg): 9502\n",
      "---\n",
      "Running seg13 ... \n",
      "Sum of training data(for this seg): 5\n",
      "Sum of testing data(for this seg): 7831\n",
      "---\n",
      "Running seg14 ... \n",
      "Sum of training data(for this seg): 6\n",
      "Sum of testing data(for this seg): 6462\n",
      "---\n",
      "Running seg15 ... \n",
      "Sum of training data(for this seg): 8\n",
      "Sum of testing data(for this seg): 5431\n",
      "---\n",
      "Running seg16 ... \n",
      "Sum of training data(for this seg): 5\n",
      "Sum of testing data(for this seg): 4575\n",
      "---\n",
      "Running seg17 ... \n",
      "Sum of training data(for this seg): 2\n",
      "Sum of testing data(for this seg): 3919\n",
      "---\n",
      "Running seg18 ... \n",
      "Sum of training data(for this seg): 5\n",
      "Sum of testing data(for this seg): 3365\n",
      "---\n",
      "Running seg19 ... \n",
      "Sum of training data(for this seg): 2\n",
      "Sum of testing data(for this seg): 2932\n",
      "---\n",
      "Running seg20 ... \n",
      "Sum of training data(for this seg): 2\n",
      "Sum of testing data(for this seg): 2560\n",
      "---\n",
      "Training set has 769 rows and 40 columns\n",
      " Testing set has 751681 rows and 40 columns\n",
      "testingLabel finish!\n",
      "all Accuracy: 62.077264158599185%\n",
      "all Accuracy: 62.07721370796083%\n",
      "      both1   l1r0   l0r1  both0\n",
      "num                             \n",
      "2    121739  92405  24047  18601\n",
      "3     78716  45408  13781   7881\n",
      "4     54382  25684   8418   4017\n",
      "5     39036  15890   5598   2263\n",
      "6     28684  10587   3917   1442\n",
      "7     21790   7105   2806    905\n",
      "8     16860   5099   2031    611\n",
      "9     13206   3715   1545    426\n",
      "10    10550   2672   1208    319\n",
      "11     8551   2039    951    218\n",
      "12     7065   1504    763    170\n",
      "13     5862   1218    601    150\n",
      "14     4914    926    519    103\n",
      "15     4125    779    448     79\n",
      "16     3546    588    370     71\n",
      "17     3060    505    308     46\n",
      "18     2692    403    238     32\n",
      "19     2374    341    186     31\n",
      "20     2090    287    168     15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# div function: to divide data by \"num\" column\n",
    "def debug(s):\n",
    "    if DEBUG:\n",
    "        print(s)\n",
    "\n",
    "def div(a):\n",
    "    print(\"Running seg{0} ... \".format(a))\n",
    "    \n",
    "    df = pd.read_csv(\"./data/segData/df_seg%s.csv\"%a)\n",
    "    df.drop([\"Unnamed: 0\", \"MemberId\"], axis=1, inplace=True)\n",
    "    debug(\"Sum of data(for this seg): {0} \".format(len(df)))\n",
    "    \n",
    "    msk = np.random.rand(len(df)) < 0.001\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    debug(train[\"SalesOrderSlaveTotalPayment\"].max())\n",
    "    debug(train[\"SalesOrderSlaveTotalPayment\"].min())\n",
    "    \n",
    "    train[\"SalesOrderSlaveTotalPayment\"] = norm(train[\"SalesOrderSlaveTotalPayment\"])\n",
    "    # debug: max should = 1, min should = 0\n",
    "    debug(train[\"SalesOrderSlaveTotalPayment\"].max())\n",
    "    debug(train[\"SalesOrderSlaveTotalPayment\"].min())\n",
    "    \n",
    "    test[\"SalesOrderSlaveTotalPayment\"] = norm(test[\"SalesOrderSlaveTotalPayment\"])\n",
    "    \n",
    "    print(\"Sum of training data(for this seg): {0}\".format(len(train)))\n",
    "    print(\"Sum of testing data(for this seg): {0}\".format(len(test)))\n",
    "    print(\"---\")\n",
    "#     test_seg_list.append(len(test))\n",
    "    return train, test\n",
    "\n",
    "# norm function: to normalize (pandas) series data\n",
    "def norm(s):\n",
    "    result = (s - s.min())/(s.max()-s.min())\n",
    "    return(result)\n",
    "\n",
    "# get_testing_labels function: PCA\n",
    "def get_testing_labels(training_samples, training_labels, testing_samples):\n",
    "    normalizer       = Normalizer().fit(training_samples)\n",
    "    training_samples = normalizer.transform(training_samples)\n",
    "    testing_samples  = normalizer.transform(testing_samples)\n",
    "\n",
    "    pca              = PCA(n_components=0.8, whiten=True).fit(training_samples)\n",
    "    training_samples = pca.transform(training_samples)\n",
    "    testing_samples  = pca.transform(testing_samples)\n",
    "\n",
    "    svm_classifier   = SVC(C=2.8).fit(training_samples, training_labels)\n",
    "    return svm_classifier.predict(testing_samples)\n",
    "\n",
    "\n",
    "# main function\n",
    "def main():\n",
    "    \n",
    "    # --- divided df_seg2~20 into training&testing data ---\n",
    "    # choose df_seg2~20 and divide it \n",
    "    trainingData, testingData = div(2)\n",
    "    for i in range(3,21):\n",
    "        df0, df1 = div(i)\n",
    "        # concat to pre dataframe, and ignore index\n",
    "        trainingData = pd.concat([trainingData,df0],ignore_index=True)  \n",
    "        testingData = pd.concat([testingData,df1],ignore_index=True)\n",
    "        \n",
    "        debug(len(trainingData))\n",
    "        debug(len(testingData))\n",
    "    \n",
    "    # store \"num\" column at df_label before norm\n",
    "    # to check error of every seg(mean \"num\" column)\n",
    "    num = testingData[\"num\"]\n",
    "    \n",
    "    # normalize the \"num\" column\n",
    "    trainingData[\"num\"] = norm(trainingData[\"num\"])\n",
    "    testingData[\"num\"] = norm(testingData[\"num\"])\n",
    "    \n",
    "    # debug: check trainingData&testingData\n",
    "    debug(\"Sum of training data: {0}\".format(len(trainingData)))\n",
    "    debug(\"Sum of testing data: {0}\".format(len(testingData)))\n",
    "\n",
    "    # --- PCA of training&testing data ---\n",
    "    # Read training and testing data\n",
    "    training_df  = trainingData.dropna()\n",
    "    testing_df   = testingData.dropna()\n",
    "    print(\"Training set has {0[0]} rows and {0[1]} columns\".format(training_df.shape))\n",
    "    print(\" Testing set has {0[0]} rows and {0[1]} columns\".format(testing_df.shape))\n",
    "\n",
    "    # Get training samples and labels from training data\n",
    "    training_labels     = training_df[\"label\"].values\n",
    "    training_samples    = training_df.drop([\"label\"], axis = 1).values\n",
    "    # Get testing samples from testing data\n",
    "    real_testing_label  = testing_df[\"label\"]\n",
    "    testing_samples     = testing_df.drop([\"label\"], axis = 1).values\n",
    "    testing_labels      = get_testing_labels(training_samples, training_labels, testing_samples)\n",
    "\n",
    "    # Writing testing labels to CSV\n",
    "    df_label   = pd.DataFrame(testing_labels, columns=[\"label\"])\n",
    "    df_label.index     += 1\n",
    "    df_label.index.name = \"label\"\n",
    "    df_label[\"real_testing_label\"] = real_testing_label\n",
    "    df_label[\"num\"] = num\n",
    "    df_label.to_csv('./data/training&testingData/testing_labels_df.csv', sep=',', index = False)\n",
    "    print('testingLabel finish!')\n",
    "    \n",
    "    # Accuracy\n",
    "    # All accuracy\n",
    "    df_label['diff'] = df_label['real_testing_label']-df_label['label']\n",
    "    len_df = len(df_label)\n",
    "    accuracy = (len_df - df_label['diff'].abs().sum())/len_df*100\n",
    "    print(\"all Accuracy: {0}%\".format(accuracy))\n",
    "    \n",
    "    # every seg accuracy\n",
    "    df_label.dropna(inplace=True)\n",
    "    df_label_int = df_label.astype(\"int\")\n",
    "    df_label_int['diff'] = df_label_int['real_testing_label']-df_label_int['label']\n",
    "    len_df = len(df_label_int)\n",
    "    accuracy = (len_df - df_label_int['diff'].abs().sum())/len_df*100\n",
    "    print(\"all Accuracy: {0}%\".format(accuracy))\n",
    "    \n",
    "    add_column_list = [\"both1\", \"l1r0\", \"l0r1\", \"both0\"]\n",
    "        \n",
    "    state1 = True\n",
    "    state2 = True\n",
    "    \n",
    "    for column in add_column_list:\n",
    "        df_label_int[column] = 0\n",
    "        df_label_int[column][(df_label_int[\"label\"]==state1)&(df_label_int[\"real_testing_label\"]==state2)] = 1\n",
    "        state1 = (state1^state2)^True\n",
    "        state2 = state2^True\n",
    "        \n",
    "    print(df_label_int.groupby(by=\"num\")[\"both1\", \"l1r0\", \"l0r1\", \"both0\"].sum())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
